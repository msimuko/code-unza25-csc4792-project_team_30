{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f91620dd",
   "metadata": {},
   "source": [
    "# Reference Classification Model\n",
    "\n",
    "This notebook implements a machine learning pipeline to classify academic references by publication type.\n",
    "\n",
    "**Objective**: Automatically categorize bibliographic references into types like journal articles, books, theses, etc.\n",
    "\n",
    "**Approach**: \n",
    "- Text preprocessing and cleaning\n",
    "- TF-IDF feature extraction\n",
    "- Multinomial Naive Bayes classification\n",
    "- Model evaluation and performance analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58c653e4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully. Shape: (10, 2)\n",
      "Columns: ['reference_text', 'type']\n",
      "\n",
      "First few rows:\n",
      "                                      reference_text              type\n",
      "0  Smith J. (2015). Deep Learning Advances. Journ...   Journal Article\n",
      "1    Brown, A. (2020). Modern Agriculture. Springer.              Book\n",
      "2  Zimba, M. (2022). Smart Farming in Zambia. MSc...            Thesis\n",
      "3  Mwale, K. (2018). Cyber Security. Proc. of IEE...  Conference Paper\n",
      "4    WHO. (2021). Global Health Report. Geneva: WHO.            Report\n",
      "âœ… Column 'type' renamed to 'publication_type'\n",
      "\n",
      "Cleaning reference texts...\n",
      "Data after cleaning: (10, 4)\n",
      "\n",
      "Publication type distribution:\n",
      "publication_type\n",
      "Journal Article     2\n",
      "Book                2\n",
      "Thesis              2\n",
      "Report              2\n",
      "Conference Paper    1\n",
      "Web Resource        1\n",
      "Name: count, dtype: int64\n",
      "âš ï¸  WARNING: Some classes have only 1 sample. Stratification disabled.\n",
      "\n",
      "Training set size: 8\n",
      "Test set size: 2\n",
      "Training distribution:\n",
      "publication_type\n",
      "Journal Article     2\n",
      "Report              2\n",
      "Web Resource        1\n",
      "Thesis              1\n",
      "Conference Paper    1\n",
      "Book                1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Training the model...\n",
      "âœ… Model training completed!\n",
      "\n",
      "Classification Report:\n",
      "==================================================\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Book       0.00      0.00      0.00       1.0\n",
      "Journal Article       0.00      0.00      0.00       0.0\n",
      "         Report       0.00      0.00      0.00       0.0\n",
      "         Thesis       0.00      0.00      0.00       1.0\n",
      "\n",
      "       accuracy                           0.00       2.0\n",
      "      macro avg       0.00      0.00      0.00       2.0\n",
      "   weighted avg       0.00      0.00      0.00       2.0\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "==============================\n",
      "[[0 1 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 1 0]]\n",
      "\n",
      "Model Accuracy: 0.0000 (0.00%)\n",
      "\n",
      "Top 20 TF-IDF Features:\n",
      "========================================\n",
      "zambia: 0.0855\n",
      "report: 0.0828\n",
      "education: 0.0612\n",
      "security: 0.0606\n",
      "123: 0.0599\n",
      "ai: 0.0545\n",
      "development report: 0.0538\n",
      "2017: 0.0538\n",
      "2017 zambia: 0.0538\n",
      "development: 0.0538\n",
      "journal: 0.0507\n",
      "msc thesis: 0.0483\n",
      "msc: 0.0483\n",
      "2022 smart: 0.0483\n",
      "farming zambia: 0.0483\n",
      "farming: 0.0483\n",
      "2022: 0.0483\n",
      "2019 database: 0.0472\n",
      "pearson: 0.0472\n",
      "2019: 0.0472\n",
      "\n",
      "ðŸŽ¯ Testing Model on Sample References:\n",
      "=============================================\n",
      "\n",
      "Sample 1:\n",
      "Reference: Smith, J. (2023). Machine Learning in Practice. Journal of A...\n",
      "Predicted: Journal Article (Confidence: 0.335)\n",
      "\n",
      "Sample 2:\n",
      "Reference: Brown, A. (2022). Data Science Fundamentals. MIT Press, Camb...\n",
      "Predicted: Report (Confidence: 0.237)\n",
      "\n",
      "Sample 3:\n",
      "Reference: Johnson, M. (2024). Deep Learning Applications. PhD Thesis, ...\n",
      "Predicted: Journal Article (Confidence: 0.291)\n",
      "\n",
      "Sample 4:\n",
      "Reference: Wilson, K. et al. (2023). Neural Networks in Healthcare. Pro...\n",
      "Predicted: Journal Article (Confidence: 0.271)\n",
      "\n",
      "ðŸ“Š MODEL SUMMARY\n",
      "==============================\n",
      "Dataset size: 10 references\n",
      "Classes: 6\n",
      "Features extracted: 80\n",
      "Training accuracy: 1.0000\n",
      "Test accuracy: 0.0000\n",
      "\n",
      "Class distribution:\n",
      "  Journal Article: 2 samples\n",
      "  Book: 2 samples\n",
      "  Thesis: 2 samples\n",
      "  Report: 2 samples\n",
      "  Conference Paper: 1 samples\n",
      "  Web Resource: 1 samples\n",
      "\n",
      "âœ… Model is ready for classifying new references!\n",
      "To use: pipeline.predict([clean_reference('your reference here')])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add src directory to path for importing utils\n",
    "sys.path.append('../src')\n",
    "from utils import clean_reference\n",
    "\n",
    "# Cell 3 - Data Loading\n",
    "# Load the reference data\n",
    "try:\n",
    "    df = pd.read_csv('../data/references.csv')\n",
    "    print(f\"Data loaded successfully. Shape: {df.shape}\")\n",
    "    print(f\"Columns: {df.columns.tolist()}\")\n",
    "    print(\"\\nFirst few rows:\")\n",
    "    print(df.head())\n",
    "    \n",
    "    # Handle different column name formats - ADD THIS FIX\n",
    "    if 'type' in df.columns and 'publication_type' not in df.columns:\n",
    "        df['publication_type'] = df['type']\n",
    "        print(\"âœ… Column 'type' renamed to 'publication_type'\")\n",
    "    elif 'publication_type' not in df.columns and 'type' not in df.columns:\n",
    "        print(\"âŒ ERROR: No 'type' or 'publication_type' column found!\")\n",
    "        print(\"Available columns:\", df.columns.tolist())\n",
    "        raise KeyError(\"Missing required label column\")\n",
    "        \n",
    "except FileNotFoundError:\n",
    "    print(\"references.csv not found. Please ensure your data file is in the data/ directory\")\n",
    "    print(\"Expected columns: 'reference_text', 'publication_type'\")\n",
    "    # Create sample data structure for demonstration\n",
    "    df = pd.DataFrame({\n",
    "        'reference_text': ['Sample journal reference...', 'Sample book reference...'],\n",
    "        'publication_type': ['journal', 'book']\n",
    "    })\n",
    "\n",
    "# Cell 4 - Data Preprocessing\n",
    "# Clean the reference texts\n",
    "print(\"\\nCleaning reference texts...\")\n",
    "df['cleaned_reference'] = df['reference_text'].apply(clean_reference)\n",
    "\n",
    "# Remove any empty references after cleaning\n",
    "df = df[df['cleaned_reference'].str.len() > 0]\n",
    "\n",
    "print(f\"Data after cleaning: {df.shape}\")\n",
    "print(\"\\nPublication type distribution:\")\n",
    "print(df['publication_type'].value_counts())\n",
    "\n",
    "# Check if we have enough data for train-test split\n",
    "if len(df) < 4:\n",
    "    print(\"âš ï¸  WARNING: Very small dataset. Consider adding more samples for better results.\")\n",
    "\n",
    "# Cell 5 - Train-Test Split\n",
    "# Split the data\n",
    "X = df['cleaned_reference']\n",
    "y = df['publication_type']\n",
    "\n",
    "# Adjust test_size based on dataset size\n",
    "test_size = 0.2 if len(df) >= 10 else 0.3\n",
    "min_samples_per_class = y.value_counts().min()\n",
    "\n",
    "if min_samples_per_class < 2:\n",
    "    print(\"âš ï¸  WARNING: Some classes have only 1 sample. Stratification disabled.\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=42\n",
    "    )\n",
    "else:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "print(f\"\\nTraining set size: {len(X_train)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")\n",
    "print(f\"Training distribution:\")\n",
    "print(y_train.value_counts())\n",
    "\n",
    "# Cell 6 - Model Training\n",
    "# Create and train the classification pipeline\n",
    "# Adjust max_features based on dataset size\n",
    "max_features = min(5000, len(X_train) * 10)  # Reasonable upper limit\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(\n",
    "        max_features=max_features, \n",
    "        stop_words='english', \n",
    "        ngram_range=(1, 2),\n",
    "        min_df=1  # Allow features that appear in at least 1 document\n",
    "    )),\n",
    "    ('classifier', MultinomialNB(alpha=1.0))\n",
    "])\n",
    "\n",
    "print(\"\\nTraining the model...\")\n",
    "pipeline.fit(X_train, y_train)\n",
    "print(\"âœ… Model training completed!\")\n",
    "\n",
    "# Cell 7 - Model Evaluation\n",
    "# Make predictions\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(\"=\" * 50)\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(\"=\" * 30)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "# Calculate and display accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nModel Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "\n",
    "# Cell 8 - Feature Analysis\n",
    "# Get feature names and importance (top TF-IDF features)\n",
    "feature_names = pipeline.named_steps['tfidf'].get_feature_names_out()\n",
    "tfidf_matrix = pipeline.named_steps['tfidf'].transform(X_train)\n",
    "\n",
    "# Calculate mean TF-IDF scores across all documents\n",
    "tfidf_scores = tfidf_matrix.mean(axis=0).A1\n",
    "\n",
    "# Get top features (limit to available features)\n",
    "n_top_features = min(20, len(feature_names))\n",
    "top_features_idx = tfidf_scores.argsort()[-n_top_features:][::-1]\n",
    "top_features = [(feature_names[i], tfidf_scores[i]) for i in top_features_idx]\n",
    "\n",
    "print(f\"\\nTop {n_top_features} TF-IDF Features:\")\n",
    "print(\"=\" * 40)\n",
    "for feature, score in top_features:\n",
    "    print(f\"{feature}: {score:.4f}\")\n",
    "\n",
    "# Cell 9 - Sample Predictions (NEW ADDITION)\n",
    "print(\"\\nðŸŽ¯ Testing Model on Sample References:\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "# Test the model on a few sample references\n",
    "sample_refs = [\n",
    "    \"Smith, J. (2023). Machine Learning in Practice. Journal of AI Research, 15(3), 45-67.\",\n",
    "    \"Brown, A. (2022). Data Science Fundamentals. MIT Press, Cambridge.\",\n",
    "    \"Johnson, M. (2024). Deep Learning Applications. PhD Thesis, University of Technology.\",\n",
    "    \"Wilson, K. et al. (2023). Neural Networks in Healthcare. Proceedings of IEEE Conference, pp. 123-135.\"\n",
    "]\n",
    "\n",
    "for i, ref in enumerate(sample_refs, 1):\n",
    "    try:\n",
    "        cleaned_ref = clean_reference(ref)\n",
    "        if cleaned_ref:  # Only predict if cleaning was successful\n",
    "            prediction = pipeline.predict([cleaned_ref])[0]\n",
    "            confidence = max(pipeline.predict_proba([cleaned_ref])[0])\n",
    "            \n",
    "            print(f\"\\nSample {i}:\")\n",
    "            print(f\"Reference: {ref[:60]}...\")\n",
    "            print(f\"Predicted: {prediction} (Confidence: {confidence:.3f})\")\n",
    "        else:\n",
    "            print(f\"\\nSample {i}: Could not process reference\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nSample {i}: Error in prediction - {e}\")\n",
    "\n",
    "# Cell 10 - Model Summary (NEW ADDITION)\n",
    "print(f\"\\nðŸ“Š MODEL SUMMARY\")\n",
    "print(\"=\" * 30)\n",
    "print(f\"Dataset size: {len(df)} references\")\n",
    "print(f\"Classes: {len(y.unique())}\")\n",
    "print(f\"Features extracted: {len(feature_names)}\")\n",
    "print(f\"Training accuracy: {pipeline.score(X_train, y_train):.4f}\")\n",
    "print(f\"Test accuracy: {accuracy:.4f}\")\n",
    "print(f\"\\nClass distribution:\")\n",
    "for class_name, count in y.value_counts().items():\n",
    "    print(f\"  {class_name}: {count} samples\")\n",
    "\n",
    "print(f\"\\nâœ… Model is ready for classifying new references!\")\n",
    "print(\"To use: pipeline.predict([clean_reference('your reference here')])\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb06278-c49b-46e5-ad69-4203f9239f6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
